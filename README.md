# Semantic-Parsing-of-picture-descriptions
This project is part of the Softwareproject "Language, Action and Perception".

General research question:  Can we implement a model that learns a natural language from scratch through interaction?

Focused research question:  Can we teach a computer a mapping from natural language picture descriptions to a logical representation?

**Files**

* BlockPictureGenerator.py: automatically creates and saves the pictures 
* CalculCoordinates.py: used to calculate the coordinates for the picture generation in BlockPictureGenerator.py
* MatrixToLogic.py: generates logic representation for a picture, probably not needed anymore as logic interpretation is taken care of in the grammar/parser
* PictureGenerator.py: first version of script to automatically generate pictures, not used anymore (-> remove?)
* grammar.py:
* semdata.py:
* world.jpg: example picture for testing and developing of grammar.py
* world.py: included in BlockPictureGenerator.py, do we still use/need it? 
